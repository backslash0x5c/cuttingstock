import streamlit as st
import pandas as pd
import time
import pulp
from datetime import datetime
import openpyxl
from collections import defaultdict
import io

BASE_PATTERNS = {
    'D10': [4000, 4500, 5500, 6000],
    'D13': [3000, 4000, 4500, 5500, 6000, 7500],
    'D16': [4000, 4500, 5500, 6000, 7000],
    'D19': [3500, 4000, 4500, 5500, 6000],
    'D22': [4000, 4500, 5500, 6000]
}

# å…¨ã¦ã®å¾„ã®ãƒªã‚¹ãƒˆ
DIAMETERS = ["D10", "D13", "D16", "D19", "D22"]

# å…¨ã¦ã®å¾„ã§é¸æŠå¯èƒ½ãªé•·ã•ã®ãƒªã‚¹ãƒˆ
ALL_AVAILABLE_LENGTHS = sorted(
    list(set(length for lengths in BASE_PATTERNS.values() for length in lengths)), reverse=True
)

def find_cell_position(worksheet, search_text):
    for row in worksheet.iter_rows():
        for cell in row:
            if cell.value and search_text in str(cell.value):
                return cell.row, cell.column
    return None

def get_diameter_column_index(worksheet, base_row, base_col, target_diameter):
    col = base_col + 1
    max_col = worksheet.max_column
    
    while col <= max_col:
        cell_value = worksheet.cell(row=base_row, column=col).value
        if cell_value and str(cell_value).strip() == target_diameter:
            return col
        col += 1
    
    return None

def extract_cutting_data_from_sheet(worksheet, target_diameter):
    base_position = find_cell_position(worksheet, "é‰„ç­‹å¾„")
    if not base_position:
        return {}
    
    base_row, base_col = base_position
    diameter_col = get_diameter_column_index(worksheet, base_row, base_col, target_diameter)
    if not diameter_col:
        return {}
    
    cutting_data = {}
    row = base_row + 1
    max_row = worksheet.max_row
    
    while row <= max_row:
        length_cell = worksheet.cell(row=row, column=base_col+1)
        count_cell = worksheet.cell(row=row, column=diameter_col)
        
        if (length_cell.value is not None and count_cell.value is not None and
            isinstance(length_cell.value, (int, float)) and 
            isinstance(count_cell.value, (int, float)) and
            count_cell.value > 0):
            
            length = int(length_cell.value)
            count = int(count_cell.value)
            cutting_data[length] = count
        
        if length_cell.value is None or length_cell.value == '':
            empty_count = 0
            temp_row = row
            while temp_row <= min(row + 2, max_row):
                if worksheet.cell(row=temp_row, column=base_col).value is None:
                    empty_count += 1
                temp_row += 1
            if empty_count >= 3:
                break
        
        row += 1
    
    return cutting_data

def create_result_sheets(df_results, target_diameter, uploaded_file=None):
    max_items = 0
    for pattern in df_results['pattern']:
        if pd.notna(pattern):
            items = [item.strip().replace('"', '') for item in str(pattern).split(',')]
            max_items = max(max_items, len(items))

    df = df_results.copy()
    
    for i in range(1, max_items + 1):
        df[f'item_{i}'] = ''

    for index, row in df.iterrows():
        pattern = row['pattern']
        if pd.notna(pattern):
            items = [item.strip().replace('"', '') for item in str(pattern).split(',')]
            for i, item in enumerate(items):
                df.at[index, f'item_{i + 1}'] = item

    df = df.drop('pattern', axis=1)

    unique_values = set()
    for i in range(1, max_items + 1):
        col_name = f'item_{i}'
        for value in df[col_name]:
            if value and value.strip():
                unique_values.add(value.strip())

    unique_values = sorted(list(unique_values), key=lambda x: int(x) if x.isdigit() else float('inf'), reverse=True)

    count_data = []
    for index, row in df.iterrows():
        id_value = row['id']
        times_value = int(row['times']) if pd.notna(row['times']) else 0
        
        count_row = {'id': id_value}
        for value in unique_values:
            count_row[value] = 0
        
        for i in range(1, max_items + 1):
            col_name = f'item_{i}'
            item_value = row[col_name]
            if item_value and item_value.strip():
                item_value = item_value.strip()
                if item_value in count_row:
                    count_row[item_value] += times_value
        
        count_data.append(count_row)

    count_df = pd.DataFrame(count_data)

    cutting_total_row = {'id': 'åˆè¨ˆ'}
    for value in unique_values:
        cutting_total_row[str(value)] = None
    count_df = pd.concat([count_df, pd.DataFrame([cutting_total_row])], ignore_index=True)

    cutting_count_df = None
    sheet_cutting_data_all = None
    cutting_unique_values = None
    
    if uploaded_file:
        try:
            workbook = openpyxl.load_workbook(uploaded_file, data_only=True)
            
            sheet_cutting_data_all = {}
            for sheet_name in workbook.sheetnames:
                worksheet = workbook[sheet_name]
                
                sheet_cutting_data = extract_cutting_data_from_sheet(worksheet, target_diameter)
                
                if sheet_cutting_data:
                    sheet_cutting_data_all[sheet_name] = sheet_cutting_data
            
            workbook.close()
            
            if sheet_cutting_data_all:
                cutting_unique_values = set()
                for sheet_data in sheet_cutting_data_all.values():
                    cutting_unique_values.update(sheet_data.keys())
                
                cutting_unique_values = sorted(list(cutting_unique_values), 
                                             key=lambda x: int(x) if str(x).isdigit() else float('inf'), reverse=True)
                
                cutting_count_data = []
                for sheet_name, sheet_data in sheet_cutting_data_all.items():
                    count_row = {'ã‚·ãƒ¼ãƒˆå': sheet_name}
                    for value in cutting_unique_values:
                        count_row[str(value)] = sheet_data.get(value, 0)
                    
                    cutting_count_data.append(count_row)
                
                cutting_count_df = pd.DataFrame(cutting_count_data)
                
                project_total_row = {'ã‚·ãƒ¼ãƒˆå': 'åˆè¨ˆ'}
                for value in cutting_unique_values:
                    project_total_row[str(value)] = None
                cutting_count_df = pd.concat([cutting_count_df, pd.DataFrame([project_total_row])], ignore_index=True)
        
        except Exception as e:
            st.warning(f"åˆ‡æ–­é›†è¨ˆè¡¨ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    return df, count_df, cutting_count_df, sheet_cutting_data_all, cutting_unique_values

def read_cutting_data_from_xlsx(uploaded_file, target_diameter):
    try:
        workbook = openpyxl.load_workbook(uploaded_file, data_only=True)
        total_cutting_data = defaultdict(int)

        for sheet_name in workbook.sheetnames:
            worksheet = workbook[sheet_name]
            sheet_cutting_data = extract_cutting_data_from_sheet(worksheet, target_diameter)

            for length, count in sheet_cutting_data.items():
                total_cutting_data[length] += count

        workbook.close()
        return dict(total_cutting_data)

    except Exception as e:
        st.error(f"XLSXãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return {}

def read_scrap_data_from_csv(uploaded_file):
    try:
        df = pd.read_csv(uploaded_file)
        df.columns = df.columns.str.strip()

        # 3åˆ—å½¢å¼ã‚’æƒ³å®šï¼šé‰„ç­‹å¾„ã€é•·ã•ã€æœ¬æ•°
        if len(df.columns) < 3:
            st.error("CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯3åˆ—(é‰„ç­‹å¾„ã€é•·ã•ã€æœ¬æ•°)ãŒå¿…è¦ã§ã™")
            return {}

        scrap_data_by_diameter = {}
        for _, row in df.iterrows():
            diameter = str(row.iloc[0]).strip()
            length = row.iloc[1]
            count = row.iloc[2]

            if pd.notna(length) and pd.notna(count):
                try:
                    length_int = int(float(length))
                    count_int = int(float(count))
                    if length_int > 0 and count_int > 0:
                        if diameter not in scrap_data_by_diameter:
                            scrap_data_by_diameter[diameter] = {}
                        scrap_data_by_diameter[diameter][length_int] = \
                            scrap_data_by_diameter[diameter].get(length_int, 0) + count_int
                except (ValueError, TypeError):
                    continue

        return scrap_data_by_diameter

    except Exception as e:
        st.error(f"CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return {}

def validate_material_selection(cutting_data, selected_materials):
    """
    åˆ‡æ–­æŒ‡ç¤ºæ›¸ã®å†…å®¹ã¨é¸æŠã•ã‚ŒãŸææ–™é•·ã‚’ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    
    Parameters:
    - cutting_data: å¾„ã”ã¨ã®åˆ‡æ–­æŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ {å¾„: {é•·ã•: æœ¬æ•°}}
    - selected_materials: å¾„ã”ã¨ã®é¸æŠã•ã‚ŒãŸææ–™é•· {å¾„: [é•·ã•ã®ãƒªã‚¹ãƒˆ]}
    
    Returns:
    - is_valid: ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çµæœ (True/False)
    - error_messages: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
    """
    error_messages = []
    
    # åˆ‡æ–­æŒ‡ç¤ºæ›¸ã«å«ã¾ã‚Œã‚‹å¾„ã‚’ãƒã‚§ãƒƒã‚¯
    for diameter, cuts in cutting_data.items():
        if not cuts:
            continue
        
        # 1. ã“ã®å¾„ã®ææ–™é•·ãŒä¸€ã¤ã‚‚é¸æŠã•ã‚Œã¦ã„ãªã„ã‹ãƒã‚§ãƒƒã‚¯
        selected_lengths = selected_materials.get(diameter, [])
        if not selected_lengths:
            cut_lengths = sorted(cuts.keys(), reverse=True)
            error_messages.append(
                f"âŒ **{diameter}**: åˆ‡æ–­æŒ‡ç¤ºæ›¸ã« {len(cuts)}ç¨®é¡ã®åˆ‡æ–­é•·ã•ï¼ˆæœ€å¤§{max(cut_lengths)}mmï¼‰ãŒã‚ã‚Šã¾ã™ãŒã€ææ–™é•·ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“"
            )
            continue
        
        # 2. æœ€å¤§åˆ‡æ–­é•·ã•ã‚’ãƒã‚§ãƒƒã‚¯
        max_cut_length = max(cuts.keys())
        max_selected_length = max(selected_lengths)
        
        if max_cut_length > max_selected_length:
            # å¯¾å¿œå¯èƒ½ãªæœ€å°ã®ææ–™é•·ã‚’ææ¡ˆ
            available_in_base = [length for length in BASE_PATTERNS.get(diameter, []) if length >= max_cut_length]
            suggestion = f"æ¨å¥¨: {min(available_in_base)}mmä»¥ä¸Š" if available_in_base else "å¯¾å¿œå¯èƒ½ãªææ–™é•·ãŒã‚ã‚Šã¾ã›ã‚“"
            
            error_messages.append(
                f"âŒ **{diameter}**: æœ€å¤§åˆ‡æ–­é•·ã• {max_cut_length}mm ã«å¯¾ã—ã¦ã€é¸æŠã•ã‚ŒãŸææ–™é•·ã®æœ€å¤§å€¤ {max_selected_length}mm ã§ã¯å¯¾å¿œã§ãã¾ã›ã‚“ï¼ˆ{suggestion}ï¼‰"
            )
    
    is_valid = len(error_messages) == 0
    return is_valid, error_messages

def dfs(index, current_combination, current_sum, remaining_counts, sorted_numbers, max_sum, all_combinations):
    if 0 < current_sum <= max_sum:
        sorted_combo = tuple(sorted(current_combination, reverse=True))
        all_combinations.add((sorted_combo, current_sum))
    
    if current_sum > max_sum or index >= len(sorted_numbers):
        return
    
    current_number = sorted_numbers[index]
    max_count = remaining_counts[current_number]
    
    for count in range(max_count + 1):
        new_sum = current_sum + current_number * count
        
        if new_sum > max_sum:
            break
        
        new_combination = current_combination + [current_number] * count
        new_remaining = remaining_counts.copy()
        new_remaining[current_number] -= count
        
        dfs(index + 1, new_combination, new_sum, new_remaining, sorted_numbers, max_sum, all_combinations)

def find_combinations_dfs(numbers_dict, max_sum=7500):
    sorted_numbers = sorted(numbers_dict.keys(), reverse=True)
    all_combinations = set()
    
    dfs(0, [], 0, numbers_dict.copy(), sorted_numbers, max_sum, all_combinations)
    
    return [(list(combo), sum_val) for combo, sum_val in all_combinations]

def generate_all_combinations(available_rods, required_cuts):
    combinations = find_combinations_dfs(required_cuts, max(available_rods))
    combinations.sort(key=lambda x: x[1])

    available_rods.sort()
    i = 0

    all_combinations = []
    for combo, total_cut_length in combinations:
        while available_rods[i] < total_cut_length:
            i += 1
        loss = (available_rods[i] - total_cut_length) / available_rods[i]
        all_combinations.append({
            'rod_length': available_rods[i],
            'cuts': tuple(combo),
            'loss': loss,
        })
    
    all_combinations.sort(key=lambda x: x['cuts'], reverse=True)
    all_combinations.sort(key=lambda x: x['rod_length'], reverse=False)
    return all_combinations

def optimal_cutting_plan(c, a, q, time_limit=120, reuse_pattern_counts=None):
    n = len(a)
    m = len(q)

    prob = pulp.LpProblem("CuttingStockProblem", pulp.LpMinimize)
    x = [pulp.LpVariable(f"y{j+1}", lowBound=0, cat='Integer') for j in range(n)]

    if reuse_pattern_counts:
        pattern_index = 0
        for reuse_info in reuse_pattern_counts:
            pattern_count = reuse_info['pattern_count']
            rod_count = reuse_info['count']

            if pattern_count > 0:
                reuse_constraint = pulp.lpSum(x[j] for j in range(pattern_index, pattern_index + pattern_count))
                prob += reuse_constraint <= rod_count, f"Reuse_constraint_{pattern_index}"

            pattern_index += pattern_count

    objective = pulp.lpSum(c[j] * x[j] for j in range(n))
    prob += objective, "Total_Loss"

    for i in range(m):
        production_constraint = pulp.lpSum(a[j][i] * x[j] for j in range(n))
        prob += production_constraint == q[i], f"Demand_constraint_{i+1}"

    prob.solve(pulp.PULP_CBC_CMD(timeLimit=time_limit, msg=False))

    if prob.status == pulp.LpStatusOptimal:
        optimal_solution = [var.varValue for var in x]
        optimal_value = pulp.value(prob.objective)
        return optimal_solution, optimal_value
    else:
        return None, None

def recalculate_with_threshold(cutting_patterns, scrap_threshold):
    total_rod_length = 0
    used_length = 0

    for pattern in cutting_patterns:
        total_rod_length += pattern["rod_length"] * pattern["num"]
        used_length += sum(pattern["cuts"]) * pattern["num"]

    loss = total_rod_length - used_length
    yield_rate = used_length * 100 / total_rod_length if total_rod_length > 0 else 0

    scrap_below_threshold = 0
    scrap_above_threshold = []

    for pattern in cutting_patterns:
        pattern_loss = pattern["loss"]
        pattern_num = pattern["num"]
        if pattern_loss < scrap_threshold:
            scrap_below_threshold += pattern_loss * pattern_num
        else:
            scrap_above_threshold.append(
                {
                    "length": pattern_loss,
                    "count": pattern_num,
                    "rod_length": pattern["rod_length"],
                }
            )

    yield_rate_with_threshold = (
        (total_rod_length - scrap_below_threshold) * 100 / total_rod_length
        if total_rod_length > 0
        else 0
    )

    return {
        "total_rod_length": total_rod_length,
        "used_length": used_length,
        "loss": loss,
        "yield_rate": yield_rate,
        "yield_rate_with_threshold": yield_rate_with_threshold,
        "scrap_below_threshold": scrap_below_threshold,
        "scrap_above_threshold": scrap_above_threshold,
    }

def consolidate_results_by_sheet(optimization_results):
    """
    è¤‡æ•°å¾„ã®æœ€é©åŒ–çµæœã‚’ã‚·ãƒ¼ãƒˆå˜ä½ã§çµ±åˆã™ã‚‹
    åœ¨åº«ã®å–ã‚Šå‡ºã—ã¨ä¿ç®¡ã®æ“ä½œã‚‚å«ã‚ã‚‹ï¼ˆå¾„ã”ã¨ã«å€‹åˆ¥ã®è¡Œï¼‰
    ã‚·ãƒ¼ãƒˆé †åºã¯å…ƒã®XLSXãƒ•ã‚¡ã‚¤ãƒ«ã®é †ç•ªã‚’ç¶­æŒ
    
    Parameters:
    - optimization_results: å¾„ã”ã¨ã®æœ€é©åŒ–çµæœã®è¾æ›¸
    
    Returns:
    - consolidated_df: ã‚·ãƒ¼ãƒˆÃ—å¾„ã§çµ±åˆã•ã‚ŒãŸDataFrameï¼ˆåœ¨åº«æ“ä½œå«ã‚€ï¼‰
    - sheet_order: ã‚·ãƒ¼ãƒˆã®å‡¦ç†é †åºãƒªã‚¹ãƒˆï¼ˆå…ƒã®é †åºï¼‰
    - sheet_color_map: ã‚·ãƒ¼ãƒˆåã¨è‰²ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    """
    all_patterns = []

    # å„å¾„ã®çµæœã‚’åé›†
    for diameter, result in optimization_results.items():
        if not result.get("success"):
            continue

        df_results = result.get("df_results")
        if df_results is None or df_results.empty:
            continue

        # å¾„æƒ…å ±ã‚’è¿½åŠ 
        df_copy = df_results.copy()
        df_copy['å¾„'] = diameter
        all_patterns.append(df_copy)

    if not all_patterns:
        return pd.DataFrame(), [], {}

    # å…¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’çµ±åˆ
    combined_df = pd.concat(all_patterns, ignore_index=True)

    # ã‚·ãƒ¼ãƒˆåã®å‡ºç¾é †åºã‚’å–å¾—ï¼ˆã‚½ãƒ¼ãƒˆã—ãªã„ã€æœ€åˆã®å¾„ã®é †åºã‚’ä½¿ç”¨ï¼‰
    sheet_order = []
    for sheet_name in combined_df['ã‚·ãƒ¼ãƒˆå']:
        if sheet_name not in sheet_order and sheet_name != '' and pd.notna(sheet_name):
            sheet_order.append(sheet_name)

    # ã‚·ãƒ¼ãƒˆåã”ã¨ã«è‰²ã‚’å‰²ã‚Šå½“ã¦
    colors = ['#e6f2ff', '#ffe6f2', '#f2ffe6', '#fff2e6', '#f2e6ff', 
              '#e6fff2', '#ffe6e6', '#f2f2ff', '#fff9e6', '#ffe6ff']
    sheet_color_map = {}
    for idx, sheet_name in enumerate(sheet_order):
        if sheet_name == 'æœªå‰²ã‚Šå½“ã¦':
            sheet_color_map[sheet_name] = '#ffcccc'
        else:
            sheet_color_map[sheet_name] = colors[idx % len(colors)]

    # ã‚·ãƒ¼ãƒˆé †åºã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ
    sheet_order_map = {name: idx for idx, name in enumerate(sheet_order)}
    combined_df['ã‚·ãƒ¼ãƒˆé †åº'] = combined_df['ã‚·ãƒ¼ãƒˆå'].map(sheet_order_map)

    # å¾„ã®é †åºãƒãƒƒãƒ”ãƒ³ã‚°
    diameter_order = {'D10': 1, 'D13': 2, 'D16': 3, 'D19': 4, 'D22': 5}
    combined_df['å¾„é †åº'] = combined_df['å¾„'].map(diameter_order)

    # 'æ“ä½œ'åˆ—ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
    has_operation = 'æ“ä½œ' in combined_df.columns

    if not has_operation:
        # æ“ä½œåˆ—ãŒãªã„å ´åˆã¯å…¨ã¦åˆ‡æ–­ã¨ã—ã¦æ‰±ã†
        cutting_df = combined_df.copy()
        grouped_df = cutting_df.groupby(['ã‚·ãƒ¼ãƒˆå', 'ã‚·ãƒ¼ãƒˆé †åº', 'å¾„', 'å¾„é †åº', 'base', 'pattern', 'loss'], as_index=False).size()
        grouped_df.rename(columns={'size': 'æœ¬æ•°'}, inplace=True)
        grouped_df = grouped_df.sort_values(by=['ã‚·ãƒ¼ãƒˆé †åº', 'å¾„é †åº'])
        grouped_df['çµ±åˆåˆ‡æ–­é †åº'] = range(1, len(grouped_df) + 1)
        grouped_df['æ“ä½œ'] = 'åˆ‡æ–­'
        grouped_df = grouped_df.drop(['å¾„é †åº', 'ã‚·ãƒ¼ãƒˆé †åº'], axis=1)
        return grouped_df, sheet_order, sheet_color_map

    # æ“ä½œåˆ¥ã«å‡¦ç†
    result_rows = []
    consolidated_order = 1

    for sheet_name in sheet_order:
        sheet_df = combined_df[combined_df['ã‚·ãƒ¼ãƒˆå'] == sheet_name]

        if sheet_df.empty:
            continue

        # 1. åœ¨åº«å–ã‚Šå‡ºã—æ“ä½œã‚’å¾„ã”ã¨ã«è¿½åŠ 
        withdrawal_df = sheet_df[sheet_df['æ“ä½œ'] == 'å–å‡º']
        if not withdrawal_df.empty:
            # å¾„ã§ã‚½ãƒ¼ãƒˆã—ã¦è¿½åŠ 
            for diameter in sorted(withdrawal_df['å¾„'].unique(), key=lambda x: diameter_order.get(x, 999)):
                diameter_withdrawal = withdrawal_df[withdrawal_df['å¾„'] == diameter]
                for _, row in diameter_withdrawal.iterrows():
                    result_rows.append({
                        'çµ±åˆåˆ‡æ–­é †åº': consolidated_order,
                        'ã‚·ãƒ¼ãƒˆå': sheet_name,
                        'å¾„': diameter,
                        'æ“ä½œ': 'å–å‡º',
                        'æœ¬æ•°': None,
                        'base': None,
                        'pattern': row['pattern'],
                        'loss': 0
                    })
                    consolidated_order += 1

        # 2. åˆ‡æ–­ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¿½åŠ 
        cutting_df = sheet_df[sheet_df['æ“ä½œ'] == 'åˆ‡æ–­']
        if not cutting_df.empty:
            # å¾„ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
            for diameter in sorted(cutting_df['å¾„'].unique(), key=lambda x: diameter_order.get(x, 999)):
                diameter_df = cutting_df[cutting_df['å¾„'] == diameter]

                # ãƒ‘ã‚¿ãƒ¼ãƒ³ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦æœ¬æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                grouped = diameter_df.groupby(['base', 'pattern', 'loss'], as_index=False).size()
                grouped.rename(columns={'size': 'æœ¬æ•°'}, inplace=True)

                for _, row in grouped.iterrows():
                    result_rows.append({
                        'çµ±åˆåˆ‡æ–­é †åº': consolidated_order,
                        'ã‚·ãƒ¼ãƒˆå': sheet_name,
                        'å¾„': diameter,
                        'æ“ä½œ': 'åˆ‡æ–­',
                        'æœ¬æ•°': row['æœ¬æ•°'],
                        'base': row['base'],
                        'pattern': row['pattern'],
                        'loss': row['loss']
                    })
                    consolidated_order += 1

        # 3. åœ¨åº«ä¿ç®¡æ“ä½œã‚’å¾„ã”ã¨ã«è¿½åŠ 
        storage_df = sheet_df[sheet_df['æ“ä½œ'] == 'ä¿ç®¡']
        if not storage_df.empty:
            # å¾„ã§ã‚½ãƒ¼ãƒˆã—ã¦è¿½åŠ 
            for diameter in sorted(storage_df['å¾„'].unique(), key=lambda x: diameter_order.get(x, 999)):
                diameter_storage = storage_df[storage_df['å¾„'] == diameter]
                for _, row in diameter_storage.iterrows():
                    result_rows.append({
                        'çµ±åˆåˆ‡æ–­é †åº': consolidated_order,
                        'ã‚·ãƒ¼ãƒˆå': sheet_name,
                        'å¾„': diameter,
                        'æ“ä½œ': 'ä¿ç®¡',
                        'æœ¬æ•°': None,
                        'base': None,
                        'pattern': row['pattern'],
                        'loss': 0
                    })
                    consolidated_order += 1

    # æœªå‰²ã‚Šå½“ã¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¿½åŠ 
    unassigned_df = combined_df[combined_df['ã‚·ãƒ¼ãƒˆå'] == 'æœªå‰²ã‚Šå½“ã¦']
    if not unassigned_df.empty:
        cutting_df = unassigned_df[unassigned_df['æ“ä½œ'] == 'åˆ‡æ–­']

        for diameter in sorted(cutting_df['å¾„'].unique(), key=lambda x: diameter_order.get(x, 999)):
            diameter_df = cutting_df[cutting_df['å¾„'] == diameter]

            grouped = diameter_df.groupby(['base', 'pattern', 'loss'], as_index=False).size()
            grouped.rename(columns={'size': 'æœ¬æ•°'}, inplace=True)

            for _, row in grouped.iterrows():
                result_rows.append({
                    'çµ±åˆåˆ‡æ–­é †åº': consolidated_order,
                    'ã‚·ãƒ¼ãƒˆå': 'æœªå‰²ã‚Šå½“ã¦',
                    'å¾„': diameter,
                    'æ“ä½œ': 'åˆ‡æ–­',
                    'æœ¬æ•°': row['æœ¬æ•°'],
                    'base': row['base'],
                    'pattern': row['pattern'],
                    'loss': row['loss']
                })
                consolidated_order += 1

    consolidated_result_df = pd.DataFrame(result_rows)

    # æœ¬æ•°ã¨baseã‚’æ•´æ•°å‹ã«å¤‰æ›ï¼ˆNoneã¯ä¿æŒï¼‰
    consolidated_result_df['æœ¬æ•°'] = consolidated_result_df['æœ¬æ•°'].astype('Int64')
    consolidated_result_df['base'] = consolidated_result_df['base'].astype('Int64')

    return consolidated_result_df, sheet_order, sheet_color_map

def assign_patterns_to_sheets(cutting_patterns, sheet_cutting_data_all, initial_inventory=None):
    """
    åˆ‡æ–­ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å„ã‚·ãƒ¼ãƒˆã«å‰²ã‚Šå½“ã¦ã€å®Ÿéš›ã®æ–½å·¥ãƒ•ãƒ­ãƒ¼ã«æ²¿ã£ãŸåˆ‡æ–­é †åºã‚’æ§‹æˆã™ã‚‹
    åœ¨åº«ã®å–ã‚Šå‡ºã—ã¨ä¿ç®¡ã®æ“ä½œã‚‚è¨˜éŒ²ã™ã‚‹
    
    Parameters:
    - cutting_patterns: æœ€é©åŒ–ã§å¾—ã‚‰ã‚ŒãŸåˆ‡æ–­ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒªã‚¹ãƒˆ
    - sheet_cutting_data_all: å„ã‚·ãƒ¼ãƒˆã®åˆ‡æ–­æŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ï¼ˆOrderedDictç­‰ã§é †åºä¿æŒï¼‰
    - initial_inventory: åˆæœŸåœ¨åº«ï¼ˆå†åˆ©ç”¨ç«¯æï¼‰
    
    Returns:
    - assigned_patterns: ã‚·ãƒ¼ãƒˆåã€åˆ‡æ–­é †åºã€åœ¨åº«æ“ä½œãŒè¿½åŠ ã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒªã‚¹ãƒˆ
    """
    if not sheet_cutting_data_all:
        return cutting_patterns
    
    # å„ã‚·ãƒ¼ãƒˆã®æ®‹ã‚Šåˆ‡æ–­æŒ‡ç¤ºã‚’ç®¡ç†
    remaining_cuts = {}
    for sheet_name, sheet_data in sheet_cutting_data_all.items():
        remaining_cuts[sheet_name] = sheet_data.copy()
    
    # åœ¨åº«ç®¡ç†ï¼ˆåˆ‡æ–­ã§ç”Ÿæˆã•ã‚ŒãŸãŒã¾ã ä½¿ç”¨ã•ã‚Œã¦ã„ãªã„ææ–™ï¼‰
    inventory = defaultdict(int)
    
    # åˆæœŸåœ¨åº«ãŒã‚ã‚Œã°è¨­å®š
    if initial_inventory:
        for length, count in initial_inventory.items():
            inventory[length] = count
    
    # åˆ‡æ–­ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ‹¡å¼µï¼ˆnumå›åˆ†ã‚’å€‹åˆ¥ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ï¼‰
    available_patterns = []
    for pattern in cutting_patterns:
        for _ in range(pattern['num']):
            available_patterns.append({
                'rod_length': pattern['rod_length'],
                'cuts': pattern['cuts'],
                'loss': pattern['loss']
            })
    
    # å‰²ã‚Šå½“ã¦çµæœ
    assigned_patterns = []
    cutting_order = 1
    
    # æœ€åˆã«åˆæœŸåœ¨åº«ã‚’è¨˜éŒ²ï¼ˆåˆæœŸåœ¨åº«ãŒã‚ã‚‹å ´åˆï¼‰
    if initial_inventory and any(initial_inventory.values()):
        inventory_items = {length: count for length, count in initial_inventory.items() if count > 0}
        if inventory_items:
            assigned_patterns.append({
                'cutting_order': cutting_order,
                'sheet_name': 'åˆæœŸåœ¨åº«',
                'operation': 'ä¿ç®¡',
                'inventory_items': inventory_items,
                'rod_length': None,
                'cuts': tuple(),
                'loss': 0
            })
            cutting_order += 1
    
    # ã‚·ãƒ¼ãƒˆã”ã¨ã«é †ç•ªã«å‡¦ç†ï¼ˆå…ƒã®é †åºã‚’ç¶­æŒï¼‰
    for sheet_name in sheet_cutting_data_all.keys():
        # ã‚¹ãƒ†ãƒƒãƒ—1: ã“ã®ã‚·ãƒ¼ãƒˆé–‹å§‹å‰ã®åœ¨åº«å–ã‚Šå‡ºã—æ“ä½œã‚’è¨˜éŒ²
        withdrawn_items = {}
        for length in list(remaining_cuts[sheet_name].keys()):
            need = remaining_cuts[sheet_name].get(length, 0)
            available = inventory.get(length, 0)
            use = min(need, available)
            if use > 0:
                withdrawn_items[length] = use
                inventory[length] -= use
                remaining_cuts[sheet_name][length] -= use
        
        # åœ¨åº«å–ã‚Šå‡ºã—æ“ä½œã‚’è¨˜éŒ²ï¼ˆææ–™ãŒã‚ã£ãŸå ´åˆã®ã¿ï¼‰
        if withdrawn_items:
            assigned_patterns.append({
                'cutting_order': cutting_order,
                'sheet_name': sheet_name,
                'operation': 'å–å‡º',
                'inventory_items': withdrawn_items,
                'rod_length': None,
                'cuts': tuple(),
                'loss': 0
            })
            cutting_order += 1
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: ã“ã®ã‚·ãƒ¼ãƒˆã®åˆ‡æ–­ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®Ÿè¡Œ
        while any(remaining_cuts[sheet_name].get(length, 0) > 0 for length in remaining_cuts[sheet_name]):
            # ã“ã®ã‚·ãƒ¼ãƒˆã«æœ€ã‚‚è²¢çŒ®ã™ã‚‹åˆ‡æ–­ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é¸æŠ
            best_idx = None
            best_score = -1
            
            for idx, pattern in enumerate(available_patterns):
                # ã“ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã“ã®ã‚·ãƒ¼ãƒˆã®ä¸è¶³ææ–™ã‚’ã„ãã¤å«ã‚€ã‹è¨ˆç®—
                score = sum(1 for cut in pattern['cuts'] 
                           if remaining_cuts[sheet_name].get(cut, 0) > 0)
                
                if score > best_score:
                    best_score = score
                    best_idx = idx
            
            if best_idx is None or best_score == 0:
                # ã“ã®ã‚·ãƒ¼ãƒˆã®åˆ‡æ–­æŒ‡ç¤ºã‚’æº€ãŸã›ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒãªã„å ´åˆ
                break
            
            # åˆ‡æ–­ã‚’å®Ÿè¡Œã—ã¦çµæœã«è¿½åŠ 
            pattern = available_patterns.pop(best_idx)
            assigned_patterns.append({
                'cutting_order': cutting_order,
                'sheet_name': sheet_name,
                'operation': 'åˆ‡æ–­',
                'rod_length': pattern['rod_length'],
                'cuts': pattern['cuts'],
                'loss': pattern['loss']
            })
            
            # åˆ‡æ–­ã§å¾—ã‚‰ã‚ŒãŸææ–™ã‚’ä¸€æ™‚çš„ã«ä¿æŒ
            temp_inventory = defaultdict(int)
            for cut in pattern['cuts']:
                temp_inventory[cut] += 1
            
            # ã“ã®ã‚·ãƒ¼ãƒˆã§ä½¿ç”¨ã™ã‚‹åˆ†ã‚’å·®ã—å¼•ã
            for length in list(temp_inventory.keys()):
                need = remaining_cuts[sheet_name].get(length, 0)
                use = min(need, temp_inventory[length])
                if use > 0:
                    temp_inventory[length] -= use
                    remaining_cuts[sheet_name][length] -= use
            
            # æ®‹ã£ãŸææ–™ã‚’åœ¨åº«ã«è¿½åŠ 
            for length, count in temp_inventory.items():
                if count > 0:
                    inventory[length] += count
            
            cutting_order += 1
        
        # ã‚¹ãƒ†ãƒƒãƒ—3: ã“ã®ã‚·ãƒ¼ãƒˆçµ‚äº†å¾Œã®ä¿ç®¡æ“ä½œã‚’è¨˜éŒ²ï¼ˆåœ¨åº«ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
        if any(inventory.get(length, 0) > 0 for length in inventory):
            stored_items = {length: count for length, count in inventory.items() if count > 0}
            assigned_patterns.append({
                'cutting_order': cutting_order,
                'sheet_name': sheet_name,
                'operation': 'ä¿ç®¡',
                'inventory_items': stored_items,
                'rod_length': None,
                'cuts': tuple(),
                'loss': 0
            })
            cutting_order += 1
    
    # æ®‹ã£ãŸåˆ‡æ–­ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚Œã°è¿½åŠ ï¼ˆæœªå‰²ã‚Šå½“ã¦ï¼‰
    for pattern in available_patterns:
        assigned_patterns.append({
            'cutting_order': cutting_order,
            'sheet_name': 'æœªå‰²ã‚Šå½“ã¦',
            'operation': 'åˆ‡æ–­',
            'rod_length': pattern['rod_length'],
            'cuts': pattern['cuts'],
            'loss': pattern['loss']
        })
        cutting_order += 1
    
    # æœ€çµ‚çš„ãªåœ¨åº«ã‚’è¿”ã™å€¤ã«å«ã‚ã‚‹
    final_inventory = {length: count for length, count in inventory.items() if count > 0}
    
    return assigned_patterns, final_inventory

def execute_optimizer(available_rods, required_cuts, diameter, time_limit, uploaded_file, input_method, scrap_threshold=400, reuse_rods=None):
    start_time = time.perf_counter()

    l = [int(s) for s in required_cuts.keys()]
    q = [int(s) for s in required_cuts.values()]

    reuse_pattern_counts = []
    all_combinations = []

    if reuse_rods:
        for rod_length, rod_count in reuse_rods.items():
            rod_combinations = generate_all_combinations([rod_length], required_cuts)
            pattern_count = len(rod_combinations)
            reuse_pattern_counts.append({
                'rod_length': rod_length,
                'count': rod_count,
                'pattern_count': pattern_count
            })
            all_combinations.extend(rod_combinations)

    normal_combinations = generate_all_combinations(available_rods, required_cuts)
    all_combinations.extend(normal_combinations)
    combinations_count = len(all_combinations)

    result_data = {
        "combinations_count": combinations_count,
        "available_rods": available_rods,
        "diameter": diameter,
        "uploaded_file": uploaded_file,
        "input_method": input_method,
        "reuse_rods": reuse_rods if reuse_rods else {},
    }

    if not all_combinations:
        result_data["error"] = "æœ‰åŠ¹ãªçµ„ã¿åˆã‚ã›ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
        return result_data
    else:
        a = []
        c = []
        for combo in all_combinations:
            a.append([combo['cuts'].count(i) for i in l])
            c.append(combo['loss'])

        optimal_solution, optimal_value = optimal_cutting_plan(c, a, q, time_limit, reuse_pattern_counts)

        end_time = time.perf_counter()
        processing_time = end_time - start_time

        if optimal_solution is not None:
            total_rod_length = 0
            used_length = 0
            used_list = []
            cutting_patterns = []

            used_reuse_rods = {}
            if reuse_rods:
                for rod_length in reuse_rods.keys():
                    used_reuse_rods[rod_length] = 0

            for i in range(len(all_combinations)):
                if int(optimal_solution[i]) > 0:
                    pattern = {
                        'rod_length': all_combinations[i]['rod_length'],
                        'cuts': all_combinations[i]['cuts'],
                        'loss': all_combinations[i]['rod_length'] - sum(all_combinations[i]['cuts']),
                        'num': int(optimal_solution[i])
                    }
                    cutting_patterns.append(pattern)
                    total_rod_length += all_combinations[i]['rod_length'] * int(optimal_solution[i])
                    used_length += sum(all_combinations[i]['cuts']) * int(optimal_solution[i])
                    used_list.extend(all_combinations[i]['cuts'] * int(optimal_solution[i]))

                    if reuse_rods and all_combinations[i]['rod_length'] in reuse_rods:
                        used_reuse_rods[all_combinations[i]['rod_length']] += int(optimal_solution[i])

            remaining_reuse_rods = {}
            if reuse_rods:
                for rod_length, total_count in reuse_rods.items():
                    used_count = used_reuse_rods.get(rod_length, 0)
                    remaining_count = total_count - used_count
                    if remaining_count > 0:
                        remaining_reuse_rods[rod_length] = remaining_count

            used_count = [used_list.count(i) for i in l]

            if used_count == q:
                expanded_df, count_df, cutting_count_df, sheet_cutting_data_all, cutting_unique_values = create_result_sheets(
                    pd.DataFrame([
                        {
                            'id': i + 1,
                            'times': pattern['num'],
                            'loss': pattern['loss'],
                            'base': pattern['rod_length'],
                            'pattern': ','.join(map(str, pattern['cuts'])),
                        }
                        for i, pattern in enumerate(cutting_patterns)
                    ]), diameter, uploaded_file if input_method == "XLSXãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰" else None
                )

                # åˆ‡æ–­ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ã‚·ãƒ¼ãƒˆã«å‰²ã‚Šå½“ã¦
                assigned_patterns, final_inventory = assign_patterns_to_sheets(
                    cutting_patterns,
                    sheet_cutting_data_all,
                    initial_inventory=reuse_rods if reuse_rods else None,
                )

                # åˆ‡æ–­é †åºä»˜ãçµæœã‚’ä½œæˆ
                df_results_list = []
                for i, pattern in enumerate(assigned_patterns):
                    operation = pattern.get('operation', 'åˆ‡æ–­')

                    if operation == 'åˆ‡æ–­':
                        df_results_list.append({
                            'id': i + 1,
                            'åˆ‡æ–­é †åº': pattern.get('cutting_order', i + 1),
                            'ã‚·ãƒ¼ãƒˆå': pattern.get('sheet_name', ''),
                            'æ“ä½œ': operation,
                            'base': pattern['rod_length'],
                            'pattern': ','.join(map(str, pattern['cuts'])),
                            'loss': pattern['loss'],
                        })
                    elif operation == 'å–å‡º':
                        inventory_items = pattern.get('inventory_items', {})
                        items_str = ', '.join([f"{length}mmÃ—{count}æœ¬" for length, count in sorted(inventory_items.items(), reverse=True)])
                        df_results_list.append({
                            'id': i + 1,
                            'åˆ‡æ–­é †åº': pattern.get('cutting_order', i + 1),
                            'ã‚·ãƒ¼ãƒˆå': pattern.get('sheet_name', ''),
                            'æ“ä½œ': operation,
                            'base': None,
                            'pattern': items_str,
                            'loss': 0,
                        })
                    elif operation == 'ä¿ç®¡':
                        inventory_items = pattern.get('inventory_items', {})
                        items_str = ', '.join([f"{length}mmÃ—{count}æœ¬" for length, count in sorted(inventory_items.items(), reverse=True)])
                        df_results_list.append({
                            'id': i + 1,
                            'åˆ‡æ–­é †åº': pattern.get('cutting_order', i + 1),
                            'ã‚·ãƒ¼ãƒˆå': pattern.get('sheet_name', ''),
                            'æ“ä½œ': operation,
                            'base': None,
                            'pattern': items_str,
                            'loss': 0,
                        })

                df_results = pd.DataFrame(df_results_list)
                df_results['base'] = df_results['base'].astype('Int64')

                loss = total_rod_length - used_length
                yield_rate = used_length * 100 / total_rod_length

                result_data.update(
                    {
                        "success": True,
                        "processing_time": processing_time,
                        "total_rod_length": total_rod_length,
                        "used_length": used_length,
                        "cutting_patterns": cutting_patterns,
                        "df_results": df_results,
                        "expanded_df": expanded_df,
                        "count_df": count_df,
                        "cutting_count_df": cutting_count_df,
                        "sheet_cutting_data_all": sheet_cutting_data_all,
                        "cutting_unique_values": cutting_unique_values,
                        "remaining_reuse_rods": remaining_reuse_rods,
                        "reuse_rods": reuse_rods if reuse_rods else {},
                        "final_inventory": final_inventory,
                    }
                )
            else:
                result_data["success"] = False
                result_data["error"] = (
                    f"è¦æ±‚æœ¬æ•°ã¨åˆ‡ã‚Šå‡ºã—å€‹æ•°ãŒä¸€è‡´ã—ã¾ã›ã‚“ã€‚è¦æ±‚: {q}, åˆ‡ã‚Šå‡ºã—: {used_count}"
                )
        else:
            result_data["success"] = False
            result_data["error"] = "æœ€é©è§£ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
    return result_data

def calculate_total_reuse_length(result, recalc_result):
    if not result.get("success"):
        return None

    remaining_reuse_rods = result.get("remaining_reuse_rods", {})
    scrap_above_threshold = recalc_result["scrap_above_threshold"]
    total_reuse_length = 0

    for item in scrap_above_threshold:
        total_reuse_length += item["length"] * item["count"]
    for length, count in remaining_reuse_rods.items():
        total_reuse_length += length * count

    return total_reuse_length

def display_optimization_results(result, scrap_threshold, tab_key=""):
    if not result.get("success"):
        st.error(result.get("error", "æœ€é©åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ"))
        return

    cutting_patterns = result["cutting_patterns"]
    processing_time = result["processing_time"]
    combinations_count = result["combinations_count"]
    df_results = result["df_results"]
    diameter = result["diameter"]
    expanded_df = result["expanded_df"]
    count_df = result["count_df"]
    cutting_count_df = result.get("cutting_count_df")
    cutting_unique_values = result.get("cutting_unique_values")

    recalc_result = recalculate_with_threshold(cutting_patterns, scrap_threshold)
    total_reuse_length = calculate_total_reuse_length(result, recalc_result)

    st.write(f"**åˆ‡æ–­ãƒ‘ã‚¿ãƒ¼ãƒ³çµ„ã¿åˆã‚ã›:** {combinations_count:,}")
    st.write("**å‡¦ç†æ™‚é–“:**", f"{processing_time:.2f} ç§’")
    st.success("æœ€é©åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ!")

    col_summary1, col_summary2, col_summary3 = st.columns([1, 1, 1])
    with col_summary1:
        st.metric("æ­©ç•™ã‚Šç‡(å†åˆ©ç”¨ãªã—)", f"{recalc_result['yield_rate']:.2f}%")
        st.metric("ç·ææ–™é•·", f"{recalc_result['total_rod_length']:,} mm")
    with col_summary2:
        st.metric(
            "æ­©ç•™ã‚Šç‡(å†åˆ©ç”¨ã‚ã‚Š)",
            f"{recalc_result['yield_rate_with_threshold']:.2f}%",
            delta=f"{recalc_result['yield_rate_with_threshold'] - recalc_result['yield_rate']:.2f}%",
        )
        st.metric("ç«¯æ(å†åˆ©ç”¨ãªã—)", f"{recalc_result['loss']:,} mm")
    with col_summary3:
        st.metric("å†åˆ©ç”¨ç«¯æã®ç·é•·", f"{total_reuse_length:,} mm")
        st.metric("ç«¯æ(å†åˆ©ç”¨ã‚ã‚Š)", f"{recalc_result['scrap_below_threshold']:,} mm")

    st.write("åˆ‡æ–­ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆã‚·ãƒ¼ãƒˆå‰²ã‚Šå½“ã¦é †ï¼‰")

    reuse_rods = result.get("reuse_rods", {})
    
    # ã‚·ãƒ¼ãƒˆåã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦è‰²åˆ†ã‘è¡¨ç¤º
    def highlight_sheet_rows(row):
        if row['base'] in reuse_rods:
            return ['background-color: #ffff99'] * len(row)
        else:
            # ã‚·ãƒ¼ãƒˆåã”ã¨ã«ç•°ãªã‚‹èƒŒæ™¯è‰²ï¼ˆè–„ã„è‰²ï¼‰
            sheet_colors = {
                'æœªå‰²ã‚Šå½“ã¦': 'background-color: #ffcccc',
            }
            sheet_name = row.get('ã‚·ãƒ¼ãƒˆå', '')
            if sheet_name and sheet_name != 'æœªå‰²ã‚Šå½“ã¦':
                # ã‚·ãƒ¼ãƒˆåã®ãƒãƒƒã‚·ãƒ¥å€¤ã‹ã‚‰è‰²ã‚’ç”Ÿæˆ
                color_idx = hash(sheet_name) % 5
                colors = ['#e6f2ff', '#ffe6f2', '#f2ffe6', '#fff2e6', '#f2e6ff']
                return [f'background-color: {colors[color_idx]}'] * len(row)
            elif sheet_name in sheet_colors:
                return [sheet_colors[sheet_name]] * len(row)
            else:
                return [''] * len(row)
    
    styled_df = df_results.style.apply(highlight_sheet_rows, axis=1)
    st.dataframe(styled_df, use_container_width=True)

    st.write("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    excel_buffer = io.BytesIO()
    with pd.ExcelWriter(excel_buffer, engine="openpyxl") as writer:
        expanded_df.to_excel(writer, sheet_name="æœ€é©åˆ‡æ–­ãƒ‘ã‚¿ãƒ¼ãƒ³", index=False)
        count_df.to_excel(writer, sheet_name="å‡ºåŠ›çµæœé›†è¨ˆè¡¨", index=False)
        if cutting_count_df is not None:
            cutting_count_df.to_excel(writer, sheet_name="åˆ‡æ–­æŒ‡ç¤ºé›†è¨ˆè¡¨", index=False)

    excel_buffer.seek(0)
    workbook = openpyxl.load_workbook(excel_buffer)

    if "å‡ºåŠ›çµæœé›†è¨ˆè¡¨" in workbook.sheetnames:
        ws_output = workbook["å‡ºåŠ›çµæœé›†è¨ˆè¡¨"]
        last_row = ws_output.max_row

        for col in range(2, ws_output.max_column + 1):
            col_letter = openpyxl.utils.get_column_letter(col)
            ws_output[f"{col_letter}{last_row}"] = (
                f"=SUM({col_letter}2:{col_letter}{last_row-1})"
            )

    if cutting_count_df is not None and "åˆ‡æ–­æŒ‡ç¤ºé›†è¨ˆè¡¨" in workbook.sheetnames:
        ws_cutting = workbook["åˆ‡æ–­æŒ‡ç¤ºé›†è¨ˆè¡¨"]
        last_row_cutting = ws_cutting.max_row

        for col in range(2, ws_cutting.max_column + 1):
            col_letter = openpyxl.utils.get_column_letter(col)
            ws_cutting[f"{col_letter}{last_row_cutting}"] = (
                f"=SUM({col_letter}2:{col_letter}{last_row_cutting-1})"
            )

        ws_summary = workbook.create_sheet("ã‚µãƒãƒªãƒ¼")
        ws_summary["A1"] = "å¾„"
        ws_summary["B1"] = diameter

        ws_summary["A2"] = "æ­©ç•™ã‚Šç‡(å†åˆ©ç”¨ãªã—)"
        ws_summary["B2"] = recalc_result["yield_rate"]
        ws_summary["B2"].number_format = "0.00%"
        ws_summary["B2"].value = recalc_result["yield_rate"] / 100

        ws_summary["A3"] = "ç«¯æ(å†åˆ©ç”¨ãªã—)[mm]"
        ws_summary["B3"] = recalc_result["loss"]
        ws_summary["B3"].number_format = "#,##0"

        ws_summary["A4"] = "ç«¯æé–¾å€¤"
        ws_summary["B4"] = scrap_threshold

        ws_summary["A5"] = "æ­©ç•™ã‚Šç‡(å†åˆ©ç”¨ã‚ã‚Š)"
        ws_summary["B5"] = recalc_result["yield_rate_with_threshold"]
        ws_summary["B5"].number_format = "0.00%"
        ws_summary["B5"].value = recalc_result["yield_rate_with_threshold"] / 100

        ws_summary["A6"] = "ç«¯æ(å†åˆ©ç”¨ã‚ã‚Š)[mm]"
        ws_summary["B6"] = recalc_result["scrap_below_threshold"]
        ws_summary["B6"].number_format = "#,##0"

        ws_summary["A7"] = "ç·ææ–™é•·"
        ws_summary["B7"] = recalc_result["total_rod_length"]
        ws_summary["B7"].number_format = "#,##0"

        ws_summary["A8"] = "å‡¦ç†æ™‚é–“(s)"
        ws_summary["B8"] = processing_time
        ws_summary["B8"].number_format = "#,##0.00"

        if cutting_unique_values:
            ws_summary["A10"] = "å·®åˆ†(å‡ºåŠ›çµæœ - åˆ‡æ–­æŒ‡ç¤º)"

            ws_summary["A11"] = "é•·ã•(mm)"
            ws_summary["B11"] = "å‡ºåŠ›çµæœ"
            ws_summary["C11"] = "åˆ‡æ–­æŒ‡ç¤º"
            ws_summary["D11"] = "å·®åˆ†"

            row_num = 12
            for i, value in enumerate(cutting_unique_values):
                col_letter_cutting = openpyxl.utils.get_column_letter(i + 2)
                col_letter_output = openpyxl.utils.get_column_letter(i + 2)

                ws_summary[f"A{row_num}"] = str(value)
                ws_summary[f"B{row_num}"] = (
                    f"=å‡ºåŠ›çµæœé›†è¨ˆè¡¨!{col_letter_output}{last_row}"
                )
                ws_summary[f"C{row_num}"] = (
                    f"=åˆ‡æ–­æŒ‡ç¤ºé›†è¨ˆè¡¨!{col_letter_cutting}{last_row_cutting}"
                )
                ws_summary[f"D{row_num}"] = f"=B{row_num}-C{row_num}"
                row_num += 1

        new_buffer = io.BytesIO()
        workbook.save(new_buffer)
        workbook.close()
        new_buffer.seek(0)

        st.download_button(
            label="æœ€é©åŒ–çµæœã‚·ãƒ¼ãƒˆ",
            data=new_buffer.getvalue(),
            file_name=f"result_sheet_{diameter}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key=f"excel_{tab_key}_{scrap_threshold}",
        )

def display_consolidated_reusable_scrap(optimization_results, scrap_threshold):
    """
    å…¨å¾„çµ±åˆã®å†åˆ©ç”¨ç«¯æãƒªã‚¹ãƒˆã‚’è¡¨ç¤ºãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    
    Parameters:
    - optimization_results: å¾„ã”ã¨ã®æœ€é©åŒ–çµæœã®è¾æ›¸
    - scrap_threshold: ç«¯æé–¾å€¤
    """
    st.write("---")
    st.write("### ğŸ“¥ å…¨å¾„çµ±åˆ å†åˆ©ç”¨ç«¯æãƒªã‚¹ãƒˆ")
    
    # å…¨å¾„ã®æœ€çµ‚åœ¨åº«ã¨ç«¯æã‚’çµ±åˆ
    all_reusable_scrap = []
    
    for diameter, result in optimization_results.items():
        if not result.get("success"):
            continue
        
        # æœ€çµ‚åœ¨åº«
        final_inventory = result.get("final_inventory", {})
        for length, count in final_inventory.items():
            all_reusable_scrap.append({
                'é‰„ç­‹å¾„': diameter,
                'é•·ã• (mm)': length,
                'æœ¬æ•°': count
            })
        
        # ç«¯æï¼ˆé–¾å€¤ä»¥ä¸Šï¼‰
        recalc_result = recalculate_with_threshold(result["cutting_patterns"], scrap_threshold)
        for item in recalc_result["scrap_above_threshold"]:
            all_reusable_scrap.append({
                'é‰„ç­‹å¾„': diameter,
                'é•·ã• (mm)': item['length'],
                'æœ¬æ•°': item['count']
            })
    
    if all_reusable_scrap:
        df_all_reusable = pd.DataFrame(all_reusable_scrap)
        
        # åŒã˜å¾„ãƒ»é•·ã•ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        df_all_reusable = df_all_reusable.groupby(['é‰„ç­‹å¾„', 'é•·ã• (mm)'], as_index=False)['æœ¬æ•°'].sum()
        df_all_reusable = df_all_reusable.sort_values(['é‰„ç­‹å¾„', 'é•·ã• (mm)'], ascending=[True, False])
        
        st.dataframe(df_all_reusable, use_container_width=True)
        
        csv_all_reusable = df_all_reusable.to_csv(index=False, encoding="utf-8-sig")
        
        st.download_button(
            label=f"å…¨å¾„çµ±åˆ å†åˆ©ç”¨ç«¯æãƒªã‚¹ãƒˆ (â‰¥{scrap_threshold}mm)",
            data=csv_all_reusable,
            file_name=f"reusable_scrap_all_diameters_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv",
            key=f"reuse_all_diameters_{scrap_threshold}",
        )
    else:
        st.info(f"å†åˆ©ç”¨å¯èƒ½ãªç«¯æ(â‰¥{scrap_threshold}mm)ã¯ã‚ã‚Šã¾ã›ã‚“")

def main():
    st.set_page_config(page_title="é‰„ç­‹åˆ‡æ–­æœ€é©åŒ–ã‚¢ãƒ—ãƒª", layout="wide")

    # ã‚«ã‚¹ã‚¿ãƒ CSSã§è¡Œé–“ã‚’è©°ã‚ã‚‹
    st.markdown("""
        <style>
        .stCheckbox {
            margin-bottom: -20px;
        }
        div[data-testid="column"] {
            padding-top: 0px;
            padding-bottom: 0px;
        }
        </style>
        """, unsafe_allow_html=True)

    st.title("ğŸ”§ é‰„ç­‹åˆ‡æ–­æœ€é©åŒ–ã‚¢ãƒ—ãƒª")
    st.write("é‰„ç­‹ã®åˆ‡æ–­ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æœ€é©åŒ–ã—ã€å»ƒæã‚’æœ€å°åŒ–ã—ã¾ã™ã€‚")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ä½¿ç”¨æ–¹æ³•ã‚’è¡¨ç¤º
    with st.sidebar:
        st.header("ğŸ“– ä½¿ç”¨æ–¹æ³•")
        st.markdown("""
        ### ä½¿ç”¨æ‰‹é †
        1. **ææ–™é•·ã•é¸æŠ**: ä½¿ç”¨ã™ã‚‹é‰„ç­‹å¾„ã¨ææ–™é•·ã•ã‚’ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã§é¸æŠ
        2. **æ™‚é–“è¨­å®š**: æœ€é©åŒ–è¨ˆç®—ã®åˆ¶é™æ™‚é–“ã‚’è¨­å®šï¼ˆè¤‡é›‘ãªå•é¡Œã»ã©é•·ã‚ã«è¨­å®šï¼‰
        3. **åˆ‡æ–­æŒ‡ç¤º**: XLSXãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆå…¨é‰„ç­‹å¾„ã®ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•èª­ã¿è¾¼ã¿ï¼‰
        4. **å†åˆ©ç”¨ç«¯æï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰**: æ—¢å­˜ã®ç«¯æãŒã‚ã‚‹å ´åˆã¯CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        5. **ç«¯æé–¾å€¤**: å†åˆ©ç”¨å¯èƒ½ãªç«¯æã®æœ€å°é•·ã•ã‚’è¨­å®š
        6. **æœ€é©åŒ–å®Ÿè¡Œ**: ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦æœ€é©åŒ–ã‚’å®Ÿè¡Œ
        7. **çµæœç¢ºèª**: å¾„ã”ã¨ã®ã‚¿ãƒ–ã§æ­©ç•™ã‚Šç‡ã‚„åˆ‡æ–­ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¢ºèª
        8. **ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**: å†åˆ©ç”¨ç«¯æãƒªã‚¹ãƒˆã¨æœ€é©åŒ–çµæœã‚·ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

        ### ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼
        - **XLSXãƒ•ã‚¡ã‚¤ãƒ«**: åˆ‡æ–­é›†è¨ˆè¡¨ï¼ˆã€Œé‰„ç­‹å¾„ã€åˆ—ã‚’å«ã‚€å½¢å¼ï¼‰
        - **CSVãƒ•ã‚¡ã‚¤ãƒ«**: é‰„ç­‹å¾„, ç«¯æã®é•·ã• (mm), æœ¬æ•° ã®3åˆ—å½¢å¼
        """)

    col1, col2 = st.columns([1, 1])

    with col1:
        st.header("âš™ï¸ è¨­å®š")

        # å¤‰æ•°ã®åˆæœŸåŒ–
        uploaded_file = None
        reuse_rods = {}
        st.write("ä½¿ç”¨ã™ã‚‹ææ–™é•·ã•ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„ï¼š")

        # session_stateã®åˆæœŸåŒ–
        if 'selected_materials' not in st.session_state:
            st.session_state.selected_materials = {}

        # å„é•·ã•ã”ã¨ã«ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’æ¨ªã«ä¸¦ã¹ã¦è¡¨ç¤º
        for idx, length in enumerate(ALL_AVAILABLE_LENGTHS):
            is_last = (idx == len(ALL_AVAILABLE_LENGTHS) - 1)            
            cols = st.columns(len(DIAMETERS))

            for i, diameter in enumerate(DIAMETERS):
                with cols[i]:
                    is_checked = st.checkbox(
                        f"{diameter}-{length}",
                        value=False,
                        key=f"material_{diameter}_{length}"
                    )

                    # é¸æŠçŠ¶æ…‹ã‚’ä¿å­˜
                    if diameter not in st.session_state.selected_materials:
                        st.session_state.selected_materials[diameter] = []

                    if is_checked and length not in st.session_state.selected_materials[diameter]:
                        st.session_state.selected_materials[diameter].append(length)
                    elif not is_checked and length in st.session_state.selected_materials[diameter]:
                        st.session_state.selected_materials[diameter].remove(length)

            # æœ€å¾Œã®è¡Œã®å ´åˆã¯é€šå¸¸ã®ä½™ç™½ã‚’è¿½åŠ 
            if is_last:
                st.markdown("<div style='margin-bottom: 20px;'></div>", unsafe_allow_html=True)

        selected_diameters = []
        for diameter in DIAMETERS:
            lengths = sorted(st.session_state.selected_materials.get(diameter, []))
            if lengths:
                selected_diameters.append(diameter)

        if not selected_diameters:
            st.warning("ææ–™é•·ã•ã‚’é¸æŠã—ã¦ãã ã•ã„")

        st.write("---")

        time_limit = st.number_input(
            "æœ€é©åŒ–ã®åˆ¶é™æ™‚é–“ (10~3600 ç§’)",
            min_value=10,
            max_value=3600,
            value=120,
            step=10,
            help="æœ€é©åŒ–è¨ˆç®—ã®åˆ¶é™æ™‚é–“ã‚’è¨­å®šã—ã¾ã™ã€‚å¤§ããªå•é¡Œã§ã¯æ™‚é–“ã‚’é•·ãè¨­å®šã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚"
        )
        st.write(f"ç¾åœ¨ã®è¨­å®š: {time_limit}ç§’")

        st.subheader("XLSXãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")

        uploaded_file = st.file_uploader(
            "XLSXãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
            type=['xlsx'],
            help="åˆ‡æ–­é›†è¨ˆè¡¨ã®XLSXãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
        )

        if uploaded_file is not None:
            with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æä¸­..."):
                # å…¨ã¦ã®é‰„ç­‹å¾„ã«ã¤ã„ã¦ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
                all_cutting_data = {}
                for diameter in DIAMETERS:
                    cutting_data = read_cutting_data_from_xlsx(uploaded_file, diameter)
                    if cutting_data:
                        all_cutting_data[diameter] = cutting_data

            if all_cutting_data:
                st.success(f"XLSXãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ­£å¸¸ã«èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚{len(all_cutting_data)}ç¨®é¡ã®å¾„ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")

                # èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’å¾„ã”ã¨ã«è¡¨ç¤º
                for diameter in DIAMETERS:
                    if diameter in all_cutting_data:
                        with st.expander(f"**{diameter}ã®åˆ‡æ–­æŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿**"):
                            df_preview = pd.DataFrame([
                                {'é•·ã• (mm)': length, 'æœ¬æ•°': count}
                                for length, count in sorted(all_cutting_data[diameter].items(), reverse=True)
                            ])
                            st.dataframe(df_preview, use_container_width=True)

                            total_pieces = sum(all_cutting_data[diameter].values())
                            cutting_types = len(all_cutting_data[diameter])
                            st.write(f"åˆ‡æ–­ç¨®é¡æ•°: {cutting_types}ç¨®é¡, ç·åˆ‡æ–­æœ¬æ•°: {total_pieces:,}æœ¬")

                # session_stateã«ä¿å­˜
                st.session_state.xlsx_cutting_data = all_cutting_data
            else:
                st.error("XLSXãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                if 'xlsx_cutting_data' in st.session_state:
                    del st.session_state.xlsx_cutting_data
        else:
            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã‚¯ãƒªã‚¢
            if 'xlsx_cutting_data' in st.session_state:
                del st.session_state.xlsx_cutting_data

        st.subheader("å†åˆ©ç”¨ç«¯æ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)")
        scrap_csv_file = st.file_uploader(
            "å†åˆ©ç”¨ç«¯æã®CSVãƒ•ã‚¡ã‚¤ãƒ« (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)",
            type=["csv"],
            help="é‰„ç­‹å¾„,é•·ã• (mm),æœ¬æ•° ã®å½¢å¼ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
            key="scrap_csv_uploader",
        )

        if scrap_csv_file is not None:
            with st.spinner("ç«¯æCSVã‚’è§£æä¸­..."):
                scrap_data_by_diameter = read_scrap_data_from_csv(scrap_csv_file)

            if scrap_data_by_diameter:
                st.success(f"å†åˆ©ç”¨ç«¯æã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ­£å¸¸ã«èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")

                st.write("**èª­ã¿è¾¼ã¾ã‚ŒãŸå†åˆ©ç”¨ç«¯æ:**")

                # å¾„ã”ã¨ã«è¡¨ç¤º
                for diameter in DIAMETERS:
                    if diameter in scrap_data_by_diameter:
                        with st.expander(f"**{diameter}ã®å†åˆ©ç”¨ç«¯æ**"):
                            df_scrap_preview = pd.DataFrame(
                                [
                                    {"é•·ã• (mm)": length, "æœ¬æ•°": count}
                                    for length, count in sorted(
                                        scrap_data_by_diameter[diameter].items(), reverse=True
                                    )
                                ]
                            )
                            st.dataframe(df_scrap_preview, use_container_width=True)

                            total_scrap_pieces = sum(scrap_data_by_diameter[diameter].values())
                            scrap_types = len(scrap_data_by_diameter[diameter])
                            st.write(
                                f"ç«¯æç¨®é¡æ•°: {scrap_types}ç¨®é¡, ç·ç«¯ææœ¬æ•°: {total_scrap_pieces:,}æœ¬"
                            )

                # session_stateã«ä¿å­˜
                st.session_state.scrap_data_by_diameter = scrap_data_by_diameter
            else:
                st.error("å†åˆ©ç”¨ç«¯æã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                if "scrap_data_by_diameter" in st.session_state:
                    del st.session_state.scrap_data_by_diameter
        else:
            if "scrap_data_by_diameter" in st.session_state:
                del st.session_state.scrap_data_by_diameter

    with col2:
        st.header("ğŸ¯ æœ€é©åŒ–çµæœ")

        scrap_threshold = st.number_input(
            "ç«¯æé–¾å€¤ (mm)",
            min_value=0,
            max_value=2000,
            value=400,
            step=50,
            help="ã“ã®é–¾å€¤æœªæº€ã®ç«¯æã®ã¿ã‚’å»ƒæã¨ã—ã¦æ­©ç•™ã‚Šç‡ã‚’è¨ˆç®—ã—ã¾ã™ã€‚é–¾å€¤ä»¥ä¸Šã®ç«¯æã¯å†åˆ©ç”¨å¯èƒ½ã¨ã—ã¦æ‰±ã‚ã‚Œã¾ã™ã€‚"
        )
        st.write(f"ç¾åœ¨ã®è¨­å®š: {scrap_threshold}mmæœªæº€ã‚’å»ƒæã¨ã—ã¦æ‰±ã†")

        if 'optimization_results' not in st.session_state:
            st.session_state.optimization_results = {}

        # æœ€é©åŒ–å®Ÿè¡Œã®æº–å‚™
        can_execute = False
        execution_data = {}

        if 'xlsx_cutting_data' in st.session_state and st.session_state.xlsx_cutting_data:
            can_execute = True
            execution_data = st.session_state.xlsx_cutting_data

        if st.button("æœ€é©åŒ–ã‚’å®Ÿè¡Œ", type="primary") and can_execute:
            st.session_state.optimization_results = {}
            st.session_state.optimization_attempted = True  # å®Ÿè¡Œè©¦è¡Œãƒ•ãƒ©ã‚°

            # ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã§é¸æŠã•ã‚Œã¦ã„ã‚‹å¾„ã‚’å–å¾—
            selected_diameters = [d for d in DIAMETERS if st.session_state.selected_materials.get(d, [])]

            if not selected_diameters:
                st.error("ææ–™é•·ã•ã‚’é¸æŠã—ã¦ãã ã•ã„")
            else:
                # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
                is_valid, error_messages = validate_material_selection(
                    execution_data, 
                    st.session_state.selected_materials
                )

                if not is_valid:
                    st.error("**é¸æŠã•ã‚ŒãŸææ–™é•·ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ï¼š**")
                    for msg in error_messages:
                        st.warning(msg)
                else:
                    # å„å¾„ã§æœ€é©åŒ–ã‚’å®Ÿè¡Œ
                    scrap_data_by_diameter = st.session_state.get('scrap_data_by_diameter', {})

                    for diameter in selected_diameters:
                        available_rods = sorted(st.session_state.selected_materials.get(diameter, []))

                        if not available_rods:
                            st.warning(f"{diameter}ã®ææ–™é•·ã•ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“")
                            continue

                        # åˆ‡æ–­æŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                        if diameter not in execution_data:
                            st.warning(f"{diameter}ã®åˆ‡æ–­æŒ‡ç¤ºãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                            continue

                        diameter_required_cuts = execution_data[diameter]

                        # ã“ã®å¾„ã®å†åˆ©ç”¨ç«¯æã‚’å–å¾—
                        diameter_reuse_rods = scrap_data_by_diameter.get(diameter, {})

                        with st.spinner(f"{diameter} ã®æœ€é©åŒ–ã‚’å®Ÿè¡Œä¸­..."):
                            result = execute_optimizer(
                                available_rods,
                                diameter_required_cuts,
                                diameter,
                                time_limit,
                                uploaded_file,
                                "XLSXãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
                                scrap_threshold,
                                diameter_reuse_rods if diameter_reuse_rods else None,
                            )
                            st.session_state.optimization_results[diameter] = result

        if st.session_state.optimization_results:
            # çµæœãŒã‚ã‚‹å¾„ã®ã¿ã‚’å–å¾—
            result_diameters = list(st.session_state.optimization_results.keys())

            if len(result_diameters) == 0:
                st.warning("æœ€é©åŒ–çµæœãŒã‚ã‚Šã¾ã›ã‚“")
            else:
                # ã‚·ãƒ¼ãƒˆå˜ä½ã§ã®çµ±åˆçµæœã‚’è¡¨ç¤º
                st.write("### ğŸ“‹ ã‚·ãƒ¼ãƒˆåˆ¥åˆ‡æ–­æŒ‡ç¤ºï¼ˆå…¨å¾„çµ±åˆï¼‰")

                consolidated_df, sheet_order, sheet_color_map = consolidate_results_by_sheet(st.session_state.optimization_results)

                if not consolidated_df.empty:
                    # ã‚·ãƒ¼ãƒˆåã§è‰²åˆ†ã‘è¡¨ç¤ºï¼ˆæ“ä½œã«ã‚ˆã‚‰ãšåŒã˜ã‚·ãƒ¼ãƒˆã¯åŒã˜è‰²ï¼‰
                    def highlight_sheet_rows_consolidated(row):
                        sheet_name = row.get('ã‚·ãƒ¼ãƒˆå', '')
                        color = sheet_color_map.get(sheet_name, '#ffffff')
                        return [f'background-color: {color}'] * len(row)

                    # è¡¨ç¤ºç”¨ã®DataFrameã‚’ä½œæˆ
                    display_df = consolidated_df.copy()
                    display_df['id'] = display_df['çµ±åˆåˆ‡æ–­é †åº']

                    # åˆ—ã®é †åºã‚’æ•´ç†
                    column_order = ['id', 'ã‚·ãƒ¼ãƒˆå', 'å¾„', 'æ“ä½œ', 'æœ¬æ•°', 'base', 'pattern', 'loss']
                    display_df = display_df[[col for col in column_order if col in display_df.columns]]

                    styled_df = display_df.style.apply(highlight_sheet_rows_consolidated, axis=1)
                    st.dataframe(styled_df, use_container_width=True, hide_index=True)

                    # ã‚·ãƒ¼ãƒˆåˆ¥åˆ‡æ–­é †åºã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    st.write("---")
                    st.write("**çµ±åˆçµæœãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰:**")

                    excel_buffer = io.BytesIO()
                    with pd.ExcelWriter(excel_buffer, engine="openpyxl") as writer:
                        # ã‚·ãƒ¼ãƒˆåˆ¥åˆ‡æ–­é †åº
                        display_df.to_excel(writer, sheet_name="ã‚·ãƒ¼ãƒˆåˆ¥åˆ‡æ–­é †åº", index=False)

                    excel_buffer.seek(0)

                    # openpyxlã§è‰²åˆ†ã‘ã‚’è¿½åŠ 
                    workbook = openpyxl.load_workbook(excel_buffer)
                    ws = workbook["ã‚·ãƒ¼ãƒˆåˆ¥åˆ‡æ–­é †åº"]

                    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ç‰¹å®šï¼ˆ1è¡Œç›®ï¼‰
                    header_row = 1

                    # ã‚·ãƒ¼ãƒˆååˆ—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
                    sheet_name_col_idx = None
                    for col_idx, cell in enumerate(ws[header_row], start=1):
                        if cell.value == 'ã‚·ãƒ¼ãƒˆå':
                            sheet_name_col_idx = col_idx
                            break

                    if sheet_name_col_idx:
                        # ãƒ‡ãƒ¼ã‚¿è¡Œã«è‰²ã‚’é©ç”¨ï¼ˆ2è¡Œç›®ä»¥é™ï¼‰
                        for row_idx in range(header_row + 1, ws.max_row + 1):
                            sheet_name_cell = ws.cell(row=row_idx, column=sheet_name_col_idx)
                            sheet_name = sheet_name_cell.value

                            if sheet_name and sheet_name in sheet_color_map:
                                # 16é€²æ•°ã‚«ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰ã‚’RGBå½¢å¼ã«å¤‰æ›ï¼ˆ#ã‚’é™¤ãï¼‰
                                color_hex = sheet_color_map[sheet_name].replace('#', '')
                                fill = openpyxl.styles.PatternFill(
                                    start_color=color_hex,
                                    end_color=color_hex,
                                    fill_type='solid'
                                )

                                # ãã®è¡Œã®å…¨ã‚»ãƒ«ã«èƒŒæ™¯è‰²ã‚’é©ç”¨
                                for col_idx in range(1, ws.max_column + 1):
                                    ws.cell(row=row_idx, column=col_idx).fill = fill

                    # ä¿®æ­£ã—ãŸworkbookã‚’æ–°ã—ã„ãƒãƒƒãƒ•ã‚¡ã«ä¿å­˜
                    new_buffer = io.BytesIO()
                    workbook.save(new_buffer)
                    workbook.close()
                    new_buffer.seek(0)

                    st.download_button(
                        label="ã‚·ãƒ¼ãƒˆåˆ¥åˆ‡æ–­é †åºã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=new_buffer.getvalue(),
                        file_name=f"cutting_order_by_sheet_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        key="consolidated_download"
                    )

                st.write("---")
                st.write("### ğŸ“Š å¾„åˆ¥è©³ç´°çµæœ")

                # å¾„åˆ¥ã®è©³ç´°çµæœã¯ã‚¿ãƒ–ã§è¡¨ç¤º
                if len(result_diameters) == 1:
                    # 1ã¤ã®å¾„ã®ã¿ã®å ´åˆã¯ã‚¿ãƒ–ã‚’ä½œã‚‰ãšç›´æ¥è¡¨ç¤º
                    diameter = result_diameters[0]
                    result = st.session_state.optimization_results[diameter]

                    st.write(f"**{diameter} ã®æœ€é©åŒ–çµæœ**")
                    display_optimization_results(
                        result,
                        scrap_threshold,
                        diameter
                    )
                else:
                    # è¤‡æ•°ã®å¾„ãŒã‚ã‚‹å ´åˆã¯ã‚¿ãƒ–ã§è¡¨ç¤º
                    diameter_tabs = st.tabs(result_diameters)

                    for tab_idx, diameter in enumerate(result_diameters):
                        with diameter_tabs[tab_idx]:
                            result = st.session_state.optimization_results[diameter]
                            display_optimization_results(
                                result,
                                scrap_threshold,
                                diameter
                            )
                # å…¨å¾„çµ±åˆã®å†åˆ©ç”¨ç«¯æãƒªã‚¹ãƒˆã‚’è¡¨ç¤º
                display_consolidated_reusable_scrap(st.session_state.optimization_results, scrap_threshold)
        elif not can_execute:
            st.info("XLSXãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        elif not st.session_state.get('optimization_attempted', False):
            # æœ€é©åŒ–ãŒä¸€åº¦ã‚‚è©¦è¡Œã•ã‚Œã¦ã„ãªã„å ´åˆã®ã¿ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º
            st.info("æœ€é©åŒ–ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()
